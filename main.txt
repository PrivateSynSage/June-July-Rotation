\documentclass{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage[page]{appendix}
\usepackage{subcaption}
\usepackage[]{graphicx}
\usepackage{natbib}
\usepackage{newpxtext,newpxmath}

% Meta information
\title{June/July Rotation}
\author{Ryan Young}
\date{July 2016}

% Document geometries
\setlength{\parskip}{1em}
\setlength{\parindent}{0em}

\begin{document}

\maketitle
\clearpage

\tableofcontents\clearpage

\section{Abstract}

Itinerant, multi-stable networks constitute an interesting class of networks capable of doing interesting tasks like counting, measuring duration, or intensity, even all at once\cite{miller_stimulus_2013}. Here, we wanted to investigate whether same network could account for some of the interesting network behavior noticed in by Mante et al. \cite{mante_context-dependent_2013}. To do so, we set up a simple firing rate network, and provided inputs that mimic the task. We then attempt to measure and observe the response with the same targeted dimensionality reduction technique.

\section{Introduction}

In 2013, Mante and colleagues conducted a now widely-known, interesting experiment, to better understand prefrontal computation. They looked at state space signals from a network involved in making decisions during eye saccade. Using an array of electrodes and monkeys doing a simple context-dependent task, they recorded FEF cells, most of whom had mixed information about stimuli and choice. The task had two contexts; in one, monkeys were to pay attention to the motion of dots and not color, saccading toward the dot motion, after a delay period. In the second context, they were to pay attention to the color, not the motion, saccading according to a rule, “left green, right red”\ref{fig:task}. The dynamics were then cast into a task-relevent, PCA-derived, state space. \ref{fig:attractor}.

In the state space, 100 ms after context and stimuli begin, prefrontal ensembles appear to represent all these task variables and do not seem to filter out---nor receive a filtered out copy of stimuli from posterior cortex---contextually irrelevant data. During this presentation the network concomitantly and increasingly represents impending choice. Part ways to fully representing the choice and while the dot stimuli are still on, stimulus representations abate to near their starting value.

\begin{figure}[h]
  \includegraphics[width=1\textwidth]{pic/task.png}
  \caption{Task, from Mante et al. 2013}
  \label{fig:task}
\end{figure}

\begin{figure}[h]
  \includegraphics[width=1\textwidth]{pic/datastatespace.png}
  \caption{State space, from Mante et al. 2013}
  \label{fig:attractor}
\end{figure}

Subsequently, they attempted to fit the data, using a network model, wired by FORCE learning, a trick developed in the last decade to get a randomly connected network to closely reproduce an output \cite{sussillo_generating_2009}. While the output fit well, as FORCE learning is designed to do, it is questionable whether the method actually wired a network implementation with biologic realism. The network wired under conditions that are highly unlikely be found in vivo; Unit-to-unit weights are rapidly tuned fast enough that error stay first order, at all time steps, and the network output remains close to desired output, sampling only tiny perturbations. Real networks do not rapidly quench error, and it would not be surprising if the output model did not tell you much about the brain’s implementation of decision-making. Subsequently they used this network and perturbation theory to try to understand how it mechanistically explains the biological data moving through state space.

The network model built here attempts to mimic that data, instead, using an itinerant, multi-stable, inhibition-balanced network. Its three prominent characteristics have properties seen in biological networks. To represent stimuli, it utilizes discrete low-energy attractor states—much like discretized Hopfield net states\cite{hopfield_neural_1982}. It, second, utilizes an inhibitory-balance regime, as first described by Tsodyks et al.\cite{tsodyks_paradoxical_1997} and signs of whom are noticed in natural networks \cite{tsodyks_paradoxical_1997} \cite{csicsvari_reliability_1998} \cite{ozeki_inhibitory_2009}. In this regime, strong excitatory recurrence is balanced out by strong inhibition (often from more diffuse sources). Third, the network relies on synaptic depression or noise to kick it out of an existing state after some time and shift to another, with some history dependence to previous stimuli. \footnote{strength of history, too, depends on noise, which every so often can fork off some deterministic cycle of states, which can be a mechanism that helps to reproduce.} Indeed, what we seek to have the task with this type of model, and then probe its dynamics to hopefully say more about a local circuit decision dynamic.

\section{Methods}

\subsection{Firing Rate Model}

To model the network, we use a continuous firing rate model. The variables track the average properties experienced by a group of neurons, as opposed to a spiking model, where each variable describes experiences of a cell\footnote{From this point, if ``neuron’’ or ``cell’’ is mentioned regarding this model’s elements, that should translate to ``unit’’.} The cells have three major time-varying properties governing $r_i(t)$, the input to the cell: the input to the cell (carrying task variables and calculated synaptic inputs) $I_i(t)$, synaptic inputs controlling interaction strength between cells $S_i(t)$, and finally a key depression variable per synapse $D_i(t)$ determining the drop in synaptic strength as a cell repeatedly fires. Their relationships come together in the following hierarchy of equations, starting with firing rate $$\tau_r \frac{dr_i}{dt} = -r_i(t) + \frac{r^{max}_i}{ exp \{ [ \Theta_i - I_i(t)  ] / \Delta_i  \}}$$ in which $\Theta_i$ is that cells firing threshold and $\Delta_i$ controls it’s responsiveness to current. 

Included in that current $I_i(t)$ are the synaptic currents $S_i(t)$, who follow $$ \tau_s \frac{ds_i}{dt} = -s_i(t) +  \tilde{\alpha} p_0 r_i(t) \tau_s D_i(t).$$ The $\tilde{\alpha}$ (fraction of available binding sites) and $p_0$ (the base release probability) together determine the synaptic activity increase due to action potentials $r_i(t)\tau_s$. When further scaled by $D_i(t) \in [0,1]$ it creates a drop in $\frac{ds_i}{dt}$ for persistant firing. This scaling factor drops with firing, $$\tau_{Di}\frac{dD_i}{dt} = 1 - D_i(t) - p_0 r_i(t) \tau_{Di} D_i(t).$$

Last but not least, the actual input itself. $I_j(t)$ tracks three major sources of current---synaptic, applied current, and noise---who each get a term in the equation, $$ I_j(t) = \sum_i s_i(t)W_{i\rightarrow j} + I_j^{app}(t) + \sigma\eta(t). $$

\subsection{Stimulus}

Three different stimuli were created, one for context $I_{c=1}^{app}(t) \in \{-1,1\}$, motion $I_{c=2}^{app}(t) \in \{-3,-2,...,3\}$, and color $I_{c=3}^{app}(t) \in \{-3,-2,...,3\}$. For each $I_{c}^{app}$, we select at random a fraction of neurons to receive that current. The amplitude strength and the sign opposite stimuli concepts. Two different regimes were tried to  treat ``opposites''. Onsets and offsets where modeled like in the Mante et al. work, except for the variable delay period, where here we make all trials 2 seconds long \ref{figure:input}A.

In one regime, ``opposites''---dots left versus right, color red versus green---were handled with excitatory versus inhibitory current of that population. However, it was noticed because some stimuli combinations when randomly sampled were all strong negative currents, and the network fell silent \ref{figure:input}B. I re-gauged the interactino by instead choosing for opposite concepts two non-overlapping populations to receive an excitatory stimulus, both a small fraction, about 15\% of neural units.

Because, each stimuli picked units at 

There may well be a better stimulus than these, but I felt these were alright first approximations to try.

\subsection{Connections}

\subsection{Neural Properties}

\section{Results}

\subsection{Network Tone}

\subsection{}

\section{Discussion}

\subsection{What the model may need} 

How networks of the brain pull off a decision at a circuit level remains a hard scientific problem. An excellent domain to study this network phenomena is the prefrontal cortex. Few places in the brain exhibit the sheer cosmopolitan multimodality and mixed selectivity of prefrontal cells. It has been called the ``prefrontal zoo''. Any signal relating to potential behaviorally relevant information \footnote{\textit{especially} behaviorally relevent!} can be found there---sensory, motor, limbic, and even visceral (oribitofrontally) \cite{fuster_prefrontal_2015}.

\section{Conclusion}


\bibliographystyle{unsrt}
\bibliography{Miller}




\end{document}
