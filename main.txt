\documentclass{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage[page]{appendix}
\usepackage{subcaption}
\usepackage[]{graphicx}
\usepackage{natbib}
\usepackage[default]{gfsbodoni}
% \usepackage{newpxtext,newpxmath}
\usepackage{csvsimple}

% Meta information
\title{June/July Rotation}
\author{Ryan Young}
\date{July 2016}

% Document geometries
\setlength{\parskip}{1em}
\setlength{\parindent}{0em}

\begin{document}

\maketitle
\clearpage

\tableofcontents\clearpage

\section{Abstract}

Itinerant, multi-stable networks constitute an interesting class of networks capable of doing interesting tasks like counting, measuring duration, or intensity, even all at once\cite{miller_stimulus_2013}. Here, we wanted to investigate whether same network could account for some of the interesting network behavior noticed in by Mante et al. \cite{mante_context-dependent_2013}. To do so, we set up a simple firing rate network, and provided inputs that mimic the task. We then attempt to measure and observe the response with the same targeted dimensionality reduction technique.

\section{Introduction}

In 2013, Mante and colleagues conducted a now widely-known, interesting experiment, to better understand prefrontal computation. They looked at state space signals from a network involved in making decisions during eye saccade. Using an array of electrodes and monkeys doing a simple context-dependent task, they recorded FEF cells, most of whom had mixed information about stimuli and choice. The task had two contexts; in one, monkeys were to pay attention to the motion of dots and not color, saccading toward the dot motion, after a delay period. In the second context, they were to pay attention to the color, not the motion, saccading according to a rule, ``left green, right red''\ref{fig:task}. The dynamics were then cast into a task-relevent, PCA-derived, state space. \ref{fig:attractor}.

In the state space, 100 ms after context and stimuli begin, prefrontal ensembles appear to represent all these task variables and do not seem to filter out---nor receive a filtered out copy of stimuli from posterior cortex---contextually irrelevant data. During this presentation the network concomitantly and increasingly represents impending choice. Part ways to fully representing the choice and while the dot stimuli are still on, stimulus representations abate to near their starting value.

\begin{figure}[h]
  \includegraphics[width=1\textwidth]{pic/task.png}
  \caption{Task, from Mante et al. 2013}
  \label{fig:task}
\end{figure}

\begin{figure}[h]
  \includegraphics[width=1\textwidth]{pic/datastatespace.png}
  \includegraphics[width=1\textwidth]{pic/statespace2.png}
  \caption{State space, from Mante et al. 2013}
  \label{fig:attractor}
\end{figure}

Subsequently, they attempted to fit the data, using a network model, wired by FORCE learning, a trick developed in the last decade to get a randomly connected network to closely reproduce an output \cite{sussillo_generating_2009}. While the output fit well, as FORCE learning is designed to do, it is questionable whether the method actually wired a network implementation with biologic realism. The network wired under conditions that are highly unlikely be found in vivo; Unit-to-unit weights are rapidly tuned fast enough that error stay first order, at all time steps, and the network output remains close to desired output, sampling only tiny perturbations. Real networks do not rapidly quench error, and it would not be surprising if the output model did not tell you much about the brain’s implementation of decision-making\footnote{This is suggested by a result of Moore in 1956: He showed \cite{church_moore_1956} the number of alternative internal mechanisms inside a black box constructed of elements, like circuits/automata, are infinite}. Subsequently they used this network and perturbation theory to try to understand how it mechanistically explains the biological data moving through state space.

The network model built here attempts to mimic that data, instead, using an itinerant, multi-stable, inhibition-balanced network. Its three prominent characteristics endow properties seen in biological networks. It utilizes discrete low-energy attractor states--much like discretized Hopfield nets--to represent stimuli\cite{hopfield_neural_1982}. It, second, utilizes an inhibitory-balance regime: a connection paradigm with strong excitatory recurrence balanced by powerful inhibition (often from more diffuse sources). These, likewise, explain paradoxical qualities in natural networks \cite{tsodyks_paradoxical_1997} \cite{csicsvari_reliability_1998} \cite{ozeki_inhibitory_2009}. Third, the network relies on synaptic depression or noise to kick it out of an existing state after some time and shift to another, with some history dependence to previous stimuli. \footnote{strength of history, too, depends on noise, which every so often can fork off some deterministic cycle of states, which can be a mechanism that helps to reproduce.} Indeed, what we seek to have the task with this type of model, and then probe its dynamics to hopefully say more about a local circuit decision dynamic.

\section{Methods}

\subsection{Firing Rate Model}

To model the network, we use a continuous firing rate model. The variables track the average properties experienced by a group of neurons, as opposed to a spiking model, where each variable describes experiences of a cell\footnote{From this point, if ``neuron’’ or ``cell’’ is mentioned regarding this model’s elements, that should translate to ``unit’’.} The cells have three major time-varying properties governing $r_i(t)$, the input to the cell: the input to the cell (carrying task variables and calculated synaptic inputs) $I_i(t)$, synaptic inputs controlling interaction strength between cells $S_i(t)$, and finally a key depression variable per synapse $D_i(t)$ determining the drop in synaptic strength as a cell repeatedly fires. Their relationships come together in the following hierarchy of equations, starting with firing rate $$\tau_r \frac{dr_i}{dt} = -r_i(t) + \frac{r^{max}_i}{ exp \{ [ \Theta_i - I_i(t)  ] / \Delta_i  \}}$$ in which $\Theta_i$ is that cells firing threshold and $\Delta_i$ controls it’s responsiveness to current. 

Included in that current $I_i(t)$ are the synaptic currents $S_i(t)$, who follow $$ \tau_s \frac{ds_i}{dt} = -s_i(t) +  \tilde{\alpha} p_0 r_i(t) \tau_s D_i(t).$$ The $\tilde{\alpha}$ (fraction of available binding sites) and $p_0$ (the base release probability) together determine the synaptic activity increase due to action potentials $r_i(t)\tau_s$. When further scaled by $D_i(t) \in [0,1]$ it creates a drop in $\frac{ds_i}{dt}$ for persistant firing. This scaling factor drops with firing, $$\tau_{Di}\frac{dD_i}{dt} = 1 - D_i(t) - p_0 r_i(t) \tau_{Di} D_i(t).$$

Last but not least, the actual input itself. $I_j(t)$ tracks three major sources of current---synaptic, applied current, and noise---who each get a term in the equation, $$ I_j(t) = \sum_i s_i(t)W_{i\rightarrow j} + I_j^{app}(t) + \sigma\eta(t). $$

\subsection{Stimulus}

Three different stimuli were created, one for context $I_{c=1}^{app}(t) \in \{-1,1\}$, motion $I_{c=2}^{app}(t) \in \{-3,-2,...,3\}$, and color $I_{c=3}^{app}(t) \in \{-3,-2,...,3\}$. For each $I_{c}^{app}$, we select at random a fraction of neurons to receive that current. The amplitude strength and the sign opposite stimuli concepts. Two different regimes were tried to  treat ``opposites''. Onsets and offsets where modeled like in the Mante et al. work, except for the variable delay period, where here we make all trials 2 seconds long \ref{figure:input}A.

\begin{figure}[h]
  \includegraphics[width=1\textwidth]{pic/stimuli.png}
  \caption{Stimuli}
  \label{fig:input}
\end{figure}

In one regime, ``opposites''---dots left versus right, color red versus green---were handled with excitatory versus inhibitory current of that population. However, it was noticed because some stimuli combinations when randomly sampled were all strong negative currents, and the network could be kicked out of all attractor states or fail to shift states. I re-gauged the interaction in two ways: one by raising recurrence, lowering inhibition; the other by changing the representation of an opposite from inhibitory current into two non-overlapping populations who both receive excitatory stimulus, each  a small fraction, $15\%-25\%$ of units.

Because, each stimuli picked units at random, this creates a situation where there is a $p_{frac}^2$ chance of unit selective for both stimuli, and a $p_{frac}^3$ chance for triple mixed-selectivity. For decision networks, previous work recognizes mixed selectivity as an important feature for learning complex choices\cite{fusi_why_2016}\cite{rigotti_internal_2010}.

There may well be a better ways to embed the stimuli, but these are meant a first approximations attempt.

\subsection{Connections}

We assigned strong EI and IE connections, overall weights of $320$ and $-320$, respectively; each was scaled by the average number of neurons sending out a connection of that type, per neuron. So, if there is one I-neuron $N_i=1$, its weight to all E-neurons is $-320$. If however, $N_i=5$ then average weight cuts by $5$ to $-64$.

We then progressively raise EE connections until units could be seen entering discrete attractor states, indicated by hot streaks across their firing rate rasters (Fig.\ref{fig:overunder}). Either to one of two levels were chosen. \begin{enumerate} \item Discrete attractors only within the bounds of the trial, that reset after stimuli stop (Fig \ref{fig:overunder}, left). \item Discrete attractors who often continue or itenerate in time between trials (Fig \ref{fig:overunder}, right).\end{enumerate}

We used two types of EE connections, reccurent connections and asymmetric. Recurrent connections took the form $W_{EE}^{i\rightarrow i}$ for excitatory groups connecting onto themselves\footnote{A more nuanced model of recurrence not implemented would be establishing groups of units who are considered a ``self'' and each set strongly connects within its ranks}. These connections were strong enough (among connected neurons who share stimuli) to locally overcome I-supression. Asymmetrics are E-to-E as well, but weaker, who affect the form of attractors and encourage new attractor states and when recurrent synaptic activity depressed.

Figure \ref{fig:connections} summarizes the typical connections expressed in a network instance. Not all runs had these exact weights, but the numbers remained quite close, and were varied to generate networks that would fire through the session, on only in a trial, and as well as varied for the two types of input.

\begin{figure}[h]
    \includegraphics[width=1\textwidth]{pic/connections.png}
    \caption{Connections}
    \label{fig:overallinput}
\end{figure}


In general, the input type that used negative current to represent an opposite requires a higher current to acheive firing in stable attractors. 

\section{Results}



\begin{figure}[h]
    \includegraphics[width=0.5\textwidth]{pic/al_undertrial.png}
    \includegraphics[width=0.5\textwidth]{pic/al_overtrial.png}
    \caption{Stimuli}
    \label{fig:overunder}
\end{figure}

\subsection{Network Tone}

\section{Discussion}

\subsection{What the model may need} 

How networks of the brain pull off a decision at a circuit level remains a hard scientific problem. An excellent domain to study this network phenomena is the prefrontal cortex. Few places in the brain exhibit the sheer cosmopolitan multimodality and mixed selectivity of prefrontal cells. It has been called the ``prefrontal zoo''. Any signal relating to potential behaviorally relevant information \footnote{\textit{especially} behaviorally relevent!} can be found there---sensory, motor, limbic, and even visceral (oribitofrontally) \cite{fuster_prefrontal_2015}.

\section{Conclusion}


\bibliographystyle{unsrt}
\bibliography{Miller}

\end{document}

\begin{appendices}

\section{Neural Properties}

\begin{tabular}{l|c}%
\bfseries Property & \bfseries Value% specify table head
\csvreader[]{consts.csv}{}% use head of csv as column names
%{\\\hline\givenname\ \name & \matriculation}% specify your coloumns here
\end{tabular}

\end{appendices}
